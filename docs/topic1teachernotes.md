# Mind wandering: Teachers' notes

**AW**: In some of these papers, the error bars on the Figures are wrong, because they calculated for each condition separately, while the analysis is obviously conducted on the _differences_. I've marked them as _bad graph_, below. You'll need to make sure students do not replicate this error. In some cases, there isn't a graph, but the same error has been made in a table. I've also given these the same label.

**AW**: Another issue with some papers is that the sample size is quite small (~10 participants). This isn't enough to get a good estimate of effect size, so it's possible that these studies won't replicate. I've marked them as _small sample_ below. It would be worth checking whether anyone has successfully replicated these studies with a larger sample.

**AW**: A third issue with some papers is that they use a median split. This is [bad practice](http://www.psychology.sunysb.edu/attachment/measures/content/maccallum_on_dichotomizing.pdf), so we should ensure students don't end up reproducing it. I've marked this as _dicohotomizing_, below.

**AW**: To estimate effects size for a within-subjects t-test, you need the
unstandardized difference score, and the standard deviation of the
differences. For example, in Exp. 3 of Pennycook et al. (2012), stereotype
consistent vs. congruent, the difference is 2.2 (see Table 2). The t = 2.46 and
t = diff/SE so SE = diff/t = .89. Note that means that they have either
incorrectly reported their either their t value, difference, or SE, because
they report the SE to be .021. If the SE were really .021. SE = SD/sqrt(N),
thus SD = SE * sqrt(N). So SD = .021 * sqrt(23) = .1. That would lead to a d of
about 20 if the difference is 2, which is extremely unlikely. Let's assume the
SE report is wrong (see below for reasoning). The df = 22, and hence N = 23. So
SD = .89*sqrt(23) = 4.27.  So d = 2.2/4.27 = .51.


## 1. When does our mind wander?

Although there are many papers on this topic, we've selected the ones that focus on the main effect, have a decent effect size, and a relatively simple design that's practical to implement in this class. 

### Seli et al. (2018) (_bad graph_)

Effect size is OK for intentional mindwandering (d = 0.59), and for mindwandering in general (i.e. ignoring type, partial eta-squared = .32).

### Xu & Metcalfe (2016) (_bad graph_)

Experiment 2 is key; effect size is: partial-eta-squared = .27. Students would need to develop stimuli at range of difficulties, and would need to reduce testing time. 

### Teasdale et al. (1993) (_small sample_, _bad graph_)

**CW**: Focus on Experiments 1 and 3.

**AW**: I'd say students could focus on only Experiment 1 with losing much here. The only thing Exp. 3 adds to Exp. 1 is an inconclusive manipulation of load size, right?

**AW**: Students would need to simplify the design for the purposes of this module. Experiment 1 has two w/subj factors (speed and load). They'd need to pick just one. And, if they pick load, it would need to be at the slow speed (because at fast, the load manipulation doesn't work very well). 

**CW**: Experiment 1: Estimated partial-eta-squared for the working memory load is about .5 (.55 for Experiment 1, .52 for Experiment 3). For presentation rate, it's .3.

**AW**: If keeping with auditory stimuli, you'll need to ensure that students have sufficient pairs of headphones available to them for testing -- probably worth getting these ordered through the tech office now? And I'd recommend moving from verbal to keyboard responding, as verbal responding isn't going to be easy to achieve or code in the mass-testing arrangements of this module. This means participants won't be able to keep their eyes closed ... does that matter? Students may also want to think about whether they really want people to make a free-text responding to the though probes. It might be better to switch to the technique used in some other papers where participants just report whether their thought was task-related or task-unrelated?

**CW**: I have replaced this paper with one which has a simpler design. Study 2 using tapping so no verbalisation required for that one. Probes and responses can be done on a computer with eyes open as is typically done now.


## 2. Where does our mind wander?

**AW**: Seems like a good topic. I guess my main question would be, "how do you see students following this up?".

### Baird et al. (2011) (_bad graph_)

**AW**: Students would have to simplify their analysis relative to what is reported here, because the paper involves an interaction, and for this module it needs to be a single-factor design. The obvious thing to do is to only analyze the off-task thoughts. The effect size for off-task thoughts here is sufficient, partial-eta-squared = .36

**AW**: And, presumably, we'd ask students to avoid the OSPAN part of the task, as that involves analysis techniques from PSYC519.

### Stawarczyk et al. (2011) (_bad graph_)

**CW**: Focus on Experiment 2, ignore the b/subj manipulation. Effect size is, partial-eta-squared = .27 for temporal orientation -- future more than others.

**AW**: Looks to me like that effect size mainly comes from the personal goals condition. This implies that students need to follow up that condition, rather than the control condition, to stand the best chance of finding something.

### Seli et al. (2017) (_bad graph_)

**CW**: Past vs. future effect size is partial-eta-squared = 0.25.

**AW**: Seems like a good study.

